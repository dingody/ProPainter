#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CUDA 12.4 å…¼å®¹æ€§æ£€æŸ¥è„šæœ¬
æ£€æŸ¥é¡¹ç›®ä¸­æ‰€æœ‰ä¾èµ–åº“å’ŒCUDAåŠŸèƒ½çš„å…¼å®¹æ€§
"""

import sys
import warnings
warnings.filterwarnings("ignore")

def check_pytorch_cuda():
    """æ£€æŸ¥PyTorchå’ŒCUDAå…¼å®¹æ€§"""
    print("ğŸ” æ£€æŸ¥PyTorchå’ŒCUDAå…¼å®¹æ€§...")
    
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}")
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"   GPU {i}: {props.name} ({props.total_memory // 1024**3}GB)")
            
            # æµ‹è¯•ç®€å•çš„CUDAæ“ä½œ
            try:
                x = torch.randn(10, 10).cuda()
                y = torch.randn(10, 10).cuda()
                z = torch.mm(x, y)
                print("âœ… CUDA tensoræ“ä½œæµ‹è¯•æˆåŠŸ")
            except Exception as e:
                print(f"âŒ CUDA tensoræ“ä½œå¤±è´¥: {e}")
                return False
                
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        
        # æ£€æŸ¥cuDNN
        if torch.backends.cudnn.is_available():
            print(f"âœ… cuDNNå¯ç”¨: {torch.backends.cudnn.version()}")
        else:
            print("âš ï¸  cuDNNä¸å¯ç”¨")
        
        return True
        
    except ImportError as e:
        print(f"âŒ PyTorchå¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ PyTorchæ£€æŸ¥å¤±è´¥: {e}")
        return False


def check_torchvision():
    """æ£€æŸ¥torchvisionå…¼å®¹æ€§"""
    print("\nğŸ” æ£€æŸ¥torchvisionå…¼å®¹æ€§...")
    
    try:
        import torchvision
        print(f"âœ… torchvisionç‰ˆæœ¬: {torchvision.__version__}")
        
        # æµ‹è¯•è§†é¢‘è¯»å–åŠŸèƒ½
        try:
            # è¿™ä¸ªåŠŸèƒ½åœ¨inference_propainter.pyä¸­ä½¿ç”¨
            from torchvision.io import read_video
            print("âœ… è§†é¢‘è¯»å–åŠŸèƒ½å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸  è§†é¢‘è¯»å–åŠŸèƒ½æœ‰é—®é¢˜: {e}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ torchvisionå¯¼å…¥å¤±è´¥: {e}")
        return False


def check_onnxruntime():
    """æ£€æŸ¥ONNX Runtime GPUæ”¯æŒ"""
    print("\nğŸ” æ£€æŸ¥ONNX Runtime GPUæ”¯æŒ...")
    
    try:
        import onnxruntime as ort
        print(f"âœ… ONNX Runtimeç‰ˆæœ¬: {ort.__version__}")
        
        # æ£€æŸ¥å¯ç”¨çš„æ‰§è¡Œæä¾›è€…
        providers = ort.get_available_providers()
        print(f"âœ… å¯ç”¨çš„æ‰§è¡Œæä¾›è€…: {providers}")
        
        if 'CUDAExecutionProvider' in providers:
            print("âœ… CUDAæ‰§è¡Œæä¾›è€…å¯ç”¨ - OCRå°†æ”¯æŒGPUåŠ é€Ÿ")
        else:
            print("âš ï¸  CUDAæ‰§è¡Œæä¾›è€…ä¸å¯ç”¨ - OCRå°†ä½¿ç”¨CPU")
        
        return True
        
    except ImportError as e:
        print(f"âŒ ONNX Runtimeå¯¼å…¥å¤±è´¥: {e}")
        return False


def check_rapidocr():
    """æ£€æŸ¥RapidOCRåŠŸèƒ½"""
    print("\nğŸ” æ£€æŸ¥RapidOCRåŠŸèƒ½...")
    
    try:
        from rapidocr_onnxruntime import RapidOCR
        print("âœ… RapidOCRå¯¼å…¥æˆåŠŸ")
        
        # å°è¯•åˆå§‹åŒ–OCRå¼•æ“
        try:
            ocr = RapidOCR()
            print("âœ… RapidOCRåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  RapidOCRåˆå§‹åŒ–è­¦å‘Š: {e}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ RapidOCRå¯¼å…¥å¤±è´¥: {e}")
        print("è¯·å®‰è£…: pip install rapidocr-onnxruntime")
        return False


def check_other_dependencies():
    """æ£€æŸ¥å…¶ä»–å…³é”®ä¾èµ–"""
    print("\nğŸ” æ£€æŸ¥å…¶ä»–å…³é”®ä¾èµ–...")
    
    dependencies = [
        ('cv2', 'opencv-python'),
        ('numpy', 'numpy'),
        ('scipy', 'scipy'),
        ('PIL', 'Pillow'),
        ('matplotlib', 'matplotlib'),
        ('imageio', 'imageio-ffmpeg'),
        ('av', 'av'),
    ]
    
    all_good = True
    for module, package in dependencies:
        try:
            if module == 'cv2':
                import cv2
                print(f"âœ… OpenCVç‰ˆæœ¬: {cv2.__version__}")
            elif module == 'PIL':
                from PIL import Image
                print(f"âœ… Pillowå¯ç”¨")
            else:
                exec(f"import {module}")
                print(f"âœ… {package}å¯ç”¨")
        except ImportError:
            print(f"âŒ {package}å¯¼å…¥å¤±è´¥")
            all_good = False
    
    return all_good


def check_mixed_precision():
    """æ£€æŸ¥æ··åˆç²¾åº¦æ”¯æŒ"""
    print("\nğŸ” æ£€æŸ¥æ··åˆç²¾åº¦æ”¯æŒ...")
    
    try:
        import torch
        
        if torch.cuda.is_available():
            # æµ‹è¯•autocast
            try:
                from torch.cuda.amp import autocast
                with autocast():
                    x = torch.randn(10, 10).cuda()
                    y = torch.randn(10, 10).cuda()
                    z = torch.mm(x, y)
                print("âœ… CUDAæ··åˆç²¾åº¦(autocast)æ”¯æŒ")
            except Exception as e:
                print(f"âš ï¸  CUDAæ··åˆç²¾åº¦æµ‹è¯•å¤±è´¥: {e}")
            
            # æµ‹è¯•half precision
            try:
                x = torch.randn(10, 10).cuda().half()
                y = torch.randn(10, 10).cuda().half()
                z = torch.mm(x, y)
                print("âœ… FP16åŠç²¾åº¦æ”¯æŒ")
            except Exception as e:
                print(f"âš ï¸  FP16åŠç²¾åº¦æµ‹è¯•å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ··åˆç²¾åº¦æ£€æŸ¥å¤±è´¥: {e}")
        return False


def check_memory_efficiency():
    """æ£€æŸ¥GPUå†…å­˜ç›¸å…³åŠŸèƒ½"""
    print("\nğŸ” æ£€æŸ¥GPUå†…å­˜ç®¡ç†...")
    
    try:
        import torch
        
        if torch.cuda.is_available():
            # æ£€æŸ¥å†…å­˜æ¸…ç†åŠŸèƒ½
            try:
                torch.cuda.empty_cache()
                print("âœ… CUDAç¼“å­˜æ¸…ç†åŠŸèƒ½å¯ç”¨")
            except Exception as e:
                print(f"âš ï¸  CUDAç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
            
            # æ£€æŸ¥å†…å­˜ä¿¡æ¯è·å–
            try:
                memory_allocated = torch.cuda.memory_allocated()
                memory_reserved = torch.cuda.memory_reserved()
                print(f"âœ… GPUå†…å­˜ç›‘æ§å¯ç”¨ (å·²åˆ†é…: {memory_allocated//1024**2}MB)")
            except Exception as e:
                print(f"âš ï¸  GPUå†…å­˜ç›‘æ§å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ GPUå†…å­˜ç®¡ç†æ£€æŸ¥å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æ£€æŸ¥å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ ProPainter CUDA 12.4 å…¼å®¹æ€§æ£€æŸ¥")
    print("=" * 60)
    
    checks = [
        ("PyTorchå’ŒCUDA", check_pytorch_cuda),
        ("torchvision", check_torchvision),
        ("ONNX Runtime", check_onnxruntime),
        ("RapidOCR", check_rapidocr),
        ("å…¶ä»–ä¾èµ–", check_other_dependencies),
        ("æ··åˆç²¾åº¦", check_mixed_precision),
        ("GPUå†…å­˜ç®¡ç†", check_memory_efficiency),
    ]
    
    results = []
    for name, check_func in checks:
        try:
            result = check_func()
            results.append((name, result))
        except Exception as e:
            print(f"âŒ {name}æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            results.append((name, False))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š å…¼å®¹æ€§æ£€æŸ¥æ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name:15} : {status}")
        if result:
            passed += 1
    
    print("-" * 60)
    print(f"æ€»ä½“ç»“æœ: {passed}/{total} é¡¹æ£€æŸ¥é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼é¡¹ç›®ä¸CUDA 12.4å®Œå…¨å…¼å®¹")
        return True
    elif passed >= total * 0.8:
        print("âš ï¸  å¤§éƒ¨åˆ†æ£€æŸ¥é€šè¿‡ï¼Œé¡¹ç›®åŸºæœ¬å…¼å®¹CUDA 12.4")
        print("å»ºè®®æ£€æŸ¥å¤±è´¥çš„é¡¹ç›®å¹¶è¿›è¡Œç›¸åº”è°ƒæ•´")
        return True
    else:
        print("âŒ å¤šä¸ªå…³é”®ç»„ä»¶æ£€æŸ¥å¤±è´¥ï¼Œéœ€è¦è§£å†³å…¼å®¹æ€§é—®é¢˜")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)