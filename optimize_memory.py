#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ProPainter æ˜¾å­˜ä¼˜åŒ–è„šæœ¬
é’ˆå¯¹Google ColabçŽ¯å¢ƒçš„æ˜¾å­˜ä¸è¶³é—®é¢˜æä¾›è§£å†³æ–¹æ¡ˆ
"""

import torch
import gc
import os
import sys
from pathlib import Path

def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()
        print("ðŸ§¹ GPUå†…å­˜å·²æ¸…ç†")

def get_gpu_memory_info():
    """èŽ·å–GPUå†…å­˜ä¿¡æ¯"""
    if torch.cuda.is_available():
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        allocated_memory = torch.cuda.memory_allocated(0) / 1024**3
        cached_memory = torch.cuda.memory_reserved(0) / 1024**3
        free_memory = total_memory - cached_memory
        
        print(f"ðŸ–¥ï¸  GPUå†…å­˜çŠ¶æ€:")
        print(f"   æ€»å®¹é‡: {total_memory:.2f}GB")
        print(f"   å·²åˆ†é…: {allocated_memory:.2f}GB")
        print(f"   ç¼“å­˜: {cached_memory:.2f}GB")
        print(f"   å¯ç”¨: {free_memory:.2f}GB")
        
        return {
            'total': total_memory,
            'allocated': allocated_memory,
            'cached': cached_memory,
            'free': free_memory
        }
    return None

def optimize_pytorch_memory():
    """ä¼˜åŒ–PyTorchå†…å­˜è®¾ç½®"""
    # è®¾ç½®å†…å­˜ç®¡ç†ç­–ç•¥
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    
    # è®¾ç½®å…¶ä»–ä¼˜åŒ–é€‰é¡¹
    torch.backends.cudnn.benchmark = False  # ç¦ç”¨benchmarkä»¥èŠ‚çœå†…å­˜
    torch.backends.cudnn.deterministic = True
    
    print("âš™ï¸  PyTorchå†…å­˜ä¼˜åŒ–è®¾ç½®å·²åº”ç”¨")

def recommend_settings(video_path):
    """æ ¹æ®è§†é¢‘åˆ†æžæŽ¨èè®¾ç½®"""
    import cv2
    
    print(f"ðŸ” åˆ†æžè§†é¢‘: {video_path}")
    
    try:
        cap = cv2.VideoCapture(video_path)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps if fps > 0 else 0
        cap.release()
        
        print(f"ðŸ“Š è§†é¢‘ä¿¡æ¯:")
        print(f"   åˆ†è¾¨çŽ‡: {width}x{height}")
        print(f"   å¸§çŽ‡: {fps:.2f}fps")
        print(f"   æ€»å¸§æ•°: {frame_count}")
        print(f"   æ—¶é•¿: {duration:.2f}ç§’")
        
        # èŽ·å–GPUå†…å­˜ä¿¡æ¯
        gpu_info = get_gpu_memory_info()
        
        if gpu_info:
            free_memory = gpu_info['free']
            
            # æ ¹æ®åˆ†è¾¨çŽ‡å’Œå¯ç”¨å†…å­˜æŽ¨èè®¾ç½®
            if width >= 1920:  # 1080p+
                if free_memory < 8:
                    recommended_width = 960
                    recommended_height = 540
                    subvideo_length = 10
                    print("ðŸŽ¯ æŽ¨èè®¾ç½® (è¶…ä½Žå†…å­˜æ¨¡å¼):")
                elif free_memory < 12:
                    recommended_width = 1280
                    recommended_height = 720
                    subvideo_length = 15
                    print("ðŸŽ¯ æŽ¨èè®¾ç½® (ä½Žå†…å­˜æ¨¡å¼):")
                else:
                    recommended_width = width
                    recommended_height = height
                    subvideo_length = 25
                    print("ðŸŽ¯ æŽ¨èè®¾ç½® (æ ‡å‡†æ¨¡å¼):")
            
            elif width >= 1280:  # 720p
                if free_memory < 6:
                    recommended_width = 854
                    recommended_height = 480
                    subvideo_length = 15
                    print("ðŸŽ¯ æŽ¨èè®¾ç½® (è¶…ä½Žå†…å­˜æ¨¡å¼):")
                elif free_memory < 10:
                    recommended_width = 960
                    recommended_height = 540
                    subvideo_length = 20
                    print("ðŸŽ¯ æŽ¨èè®¾ç½® (ä½Žå†…å­˜æ¨¡å¼):")
                else:
                    recommended_width = width
                    recommended_height = height
                    subvideo_length = 30
                    print("ðŸŽ¯ æŽ¨èè®¾ç½® (æ ‡å‡†æ¨¡å¼):")
            
            else:  # 480påŠä»¥ä¸‹
                recommended_width = width
                recommended_height = height
                subvideo_length = 40
                print("ðŸŽ¯ æŽ¨èè®¾ç½® (å°åˆ†è¾¨çŽ‡):")
            
            print(f"   --width {recommended_width}")
            print(f"   --height {recommended_height}")
            print(f"   --subvideo_length {subvideo_length}")
            print(f"   --fp16")
            
            return {
                'width': recommended_width,
                'height': recommended_height,
                'subvideo_length': subvideo_length
            }
    
    except Exception as e:
        print(f"âŒ è§†é¢‘åˆ†æžå¤±è´¥: {e}")
        return None

def run_optimized_inference(video_path, mask_path, custom_settings=None):
    """è¿è¡Œä¼˜åŒ–çš„æŽ¨ç†å‘½ä»¤"""
    
    # æ¸…ç†å†…å­˜
    clear_gpu_memory()
    optimize_pytorch_memory()
    
    # èŽ·å–æŽ¨èè®¾ç½®
    if custom_settings:
        settings = custom_settings
    else:
        settings = recommend_settings(video_path)
        if not settings:
            # é»˜è®¤ä¿å®ˆè®¾ç½®
            settings = {
                'width': 640,
                'height': 360,
                'subvideo_length': 10
            }
    
    # æž„å»ºå‘½ä»¤
    cmd = [
        'python', 'inference_propainter.py',
        '-i', str(video_path),
        '-m', str(mask_path),
        '--fp16',
        '--width', str(settings['width']),
        '--height', str(settings['height']),
        '--subvideo_length', str(settings['subvideo_length']),
        '--neighbor_length', '5',  # å‡å°‘é‚»è¿‘å¸§æ•°é‡
        '--ref_stride', '15'  # å¢žåŠ å‚è€ƒå¸§é—´éš”
    ]
    
    print(f"\nðŸš€ æ‰§è¡Œä¼˜åŒ–å‘½ä»¤:")
    cmd_str = ' '.join(cmd)
    print(f"   {cmd_str}")
    
    # æ‰§è¡Œå‘½ä»¤
    import subprocess
    try:
        result = subprocess.run(cmd, check=True, capture_output=False)
        print("âœ… æŽ¨ç†å®Œæˆï¼")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ æŽ¨ç†å¤±è´¥: {e}")
        return False

def progressive_processing(video_path, mask_path):
    """æ¸è¿›å¼å¤„ç†ï¼šä»Žæœ€ä¿å®ˆè®¾ç½®å¼€å§‹ï¼Œé€æ­¥æé«˜è´¨é‡"""
    
    print("ðŸ”„ æ¸è¿›å¼å¤„ç†æ¨¡å¼")
    print("ä»Žæœ€ä¿å®ˆè®¾ç½®å¼€å§‹ï¼Œé€æ­¥æé«˜è´¨é‡ç›´åˆ°æˆåŠŸ")
    
    # å®šä¹‰ä¸åŒçš„è´¨é‡çº§åˆ«
    quality_levels = [
        {
            'name': 'è¶…ä½Žè´¨é‡æ¨¡å¼ (èŠ‚çœæ˜¾å­˜)',
            'width': 480,
            'height': 270,
            'subvideo_length': 8
        },
        {
            'name': 'ä½Žè´¨é‡æ¨¡å¼',
            'width': 640,
            'height': 360,
            'subvideo_length': 12
        },
        {
            'name': 'ä¸­ç­‰è´¨é‡æ¨¡å¼',
            'width': 854,
            'height': 480,
            'subvideo_length': 16
        },
        {
            'name': 'é«˜è´¨é‡æ¨¡å¼',
            'width': 1280,
            'height': 720,
            'subvideo_length': 20
        }
    ]
    
    for i, settings in enumerate(quality_levels):
        print(f"\nðŸŽ¯ å°è¯• {settings['name']}")
        print(f"   åˆ†è¾¨çŽ‡: {settings['width']}x{settings['height']}")
        print(f"   å­è§†é¢‘é•¿åº¦: {settings['subvideo_length']}")
        
        # æ¸…ç†å†…å­˜
        clear_gpu_memory()
        
        # å°è¯•è¿è¡Œ
        success = run_optimized_inference(video_path, mask_path, settings)
        
        if success:
            print(f"âœ… æˆåŠŸå®Œæˆï¼ä½¿ç”¨è®¾ç½®: {settings['name']}")
            return True
        else:
            print(f"âŒ {settings['name']} å¤±è´¥ï¼Œå°è¯•æ›´ä¿å®ˆè®¾ç½®...")
            if i == len(quality_levels) - 1:
                print("ðŸ˜µ æ‰€æœ‰è®¾ç½®éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶æˆ–å°è¯•æ›´å°çš„è§†é¢‘")
                return False
    
    return False

def split_video_processing(video_path, mask_path, segment_duration=30):
    """åˆ†æ®µå¤„ç†ï¼šå°†é•¿è§†é¢‘åˆ†æˆå°æ®µåˆ†åˆ«å¤„ç†"""
    
    print(f"âœ‚ï¸  åˆ†æ®µå¤„ç†æ¨¡å¼ (æ¯æ®µ {segment_duration} ç§’)")
    
    import cv2
    import subprocess
    from pathlib import Path
    
    try:
        # èŽ·å–è§†é¢‘ä¿¡æ¯
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps
        cap.release()
        
        print(f"ðŸ“Š è§†é¢‘æ€»æ—¶é•¿: {duration:.2f}ç§’")
        
        # è®¡ç®—åˆ†æ®µæ•°é‡
        num_segments = int(duration / segment_duration) + 1
        print(f"ðŸ”¢ å°†åˆ†ä¸º {num_segments} æ®µå¤„ç†")
        
        video_stem = Path(video_path).stem
        output_dir = Path('temp_segments')
        output_dir.mkdir(exist_ok=True)
        
        processed_segments = []
        
        for i in range(num_segments):
            start_time = i * segment_duration
            end_time = min((i + 1) * segment_duration, duration)
            
            print(f"\nðŸŽ¬ å¤„ç†ç¬¬ {i+1}/{num_segments} æ®µ ({start_time:.1f}s - {end_time:.1f}s)")
            
            # åˆ†å‰²è§†é¢‘æ®µ
            segment_path = output_dir / f"{video_stem}_segment_{i:03d}.mp4"
            ffmpeg_cmd = [
                'ffmpeg', '-y',
                '-i', str(video_path),
                '-ss', str(start_time),
                '-t', str(end_time - start_time),
                '-c', 'copy',
                str(segment_path)
            ]
            
            subprocess.run(ffmpeg_cmd, check=True, capture_output=True)
            
            # å¤„ç†è¿™ä¸€æ®µ
            segment_mask_path = f"{mask_path}_segment_{i:03d}"
            success = run_optimized_inference(segment_path, segment_mask_path, {
                'width': 854,
                'height': 480,
                'subvideo_length': 20
            })
            
            if success:
                processed_segments.append(i)
                print(f"âœ… ç¬¬ {i+1} æ®µå¤„ç†å®Œæˆ")
            else:
                print(f"âŒ ç¬¬ {i+1} æ®µå¤„ç†å¤±è´¥")
        
        print(f"\nðŸ“Š å¤„ç†ç»“æžœ: {len(processed_segments)}/{num_segments} æ®µæˆåŠŸ")
        
        if len(processed_segments) == num_segments:
            print("ðŸŽ‰ æ‰€æœ‰æ®µéƒ½å¤„ç†æˆåŠŸï¼")
            print("ðŸ’¡ æç¤º: å¯ä»¥ä½¿ç”¨è§†é¢‘ç¼–è¾‘è½¯ä»¶å°†ç»“æžœæ®µåˆå¹¶")
            return True
        else:
            print("âš ï¸  éƒ¨åˆ†æ®µå¤„ç†å¤±è´¥")
            return False
    
    except Exception as e:
        print(f"âŒ åˆ†æ®µå¤„ç†å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ProPainter æ˜¾å­˜ä¼˜åŒ–å¤„ç†")
    parser.add_argument('-i', '--input', type=str, required=True, help='è¾“å…¥è§†é¢‘è·¯å¾„')
    parser.add_argument('-m', '--mask', type=str, required=True, help='æŽ©ç æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--mode', type=str, choices=['auto', 'progressive', 'split'], 
                       default='auto', help='å¤„ç†æ¨¡å¼')
    parser.add_argument('--segment-duration', type=int, default=30,
                       help='åˆ†æ®µæ¨¡å¼çš„æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    print("ðŸ’¾ ProPainter æ˜¾å­˜ä¼˜åŒ–å¤„ç†")
    print("=" * 50)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    if not os.path.exists(args.mask):
        print(f"âŒ æŽ©ç æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {args.mask}")
        return
    
    # åˆå§‹å†…å­˜çŠ¶æ€
    get_gpu_memory_info()
    
    if args.mode == 'auto':
        print("\nðŸŽ¯ è‡ªåŠ¨ä¼˜åŒ–æ¨¡å¼")
        success = run_optimized_inference(args.input, args.mask)
    elif args.mode == 'progressive':
        print("\nðŸ”„ æ¸è¿›å¼å¤„ç†æ¨¡å¼")
        success = progressive_processing(args.input, args.mask)
    elif args.mode == 'split':
        print("\nâœ‚ï¸  åˆ†æ®µå¤„ç†æ¨¡å¼")
        success = split_video_processing(args.input, args.mask, args.segment_duration)
    
    if success:
        print("\nðŸŽ‰ å¤„ç†å®Œæˆï¼")
    else:
        print("\nâŒ å¤„ç†å¤±è´¥ï¼Œè¯·å°è¯•å…¶ä»–æ¨¡å¼æˆ–å‡å°è§†é¢‘åˆ†è¾¨çŽ‡")

if __name__ == "__main__":
    main()