#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ProPainter Colabåˆå§‹åŒ–è„šæœ¬
ä¸“ä¸ºGoogle Colabç¯å¢ƒä¼˜åŒ–çš„å¿«é€Ÿåˆå§‹åŒ–è„šæœ¬
"""

def init_propainter_colab():
    """
    Google Colabä¸“ç”¨çš„ProPainteråˆå§‹åŒ–å‡½æ•°
    ä¸€é”®å®Œæˆæ‰€æœ‰ç¯å¢ƒé…ç½®å’Œæ¨¡å‹ä¸‹è½½
    """
    
    print("ğŸš€ ProPainter Colab ç¯å¢ƒåˆå§‹åŒ–")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ç¯å¢ƒ
    print("1ï¸âƒ£ æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    import torch
    import os
    import sys
    from pathlib import Path
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… GPU: {gpu_name} ({gpu_memory:.1f}GB)")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    # æ£€æŸ¥å½“å‰ç›®å½•
    current_dir = Path.cwd()
    print(f"ğŸ“ å½“å‰ç›®å½•: {current_dir}")
    
    # 2. å®‰è£…ä¾èµ–
    print(f"\n2ï¸âƒ£ æ£€æŸ¥Pythonä¾èµ–...")
    
    required_packages = [
        'torch', 'torchvision', 'opencv-python', 'numpy', 
        'scipy', 'pillow', 'tqdm', 'requests', 'rapidocr'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            if package == 'opencv-python':
                import cv2
            elif package == 'pillow':
                import PIL
            elif package == 'rapidocr':
                from rapidocr import RapidOCR
            else:
                __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            missing_packages.append(package)
            print(f"âŒ {package} - éœ€è¦å®‰è£…")
    
    if missing_packages:
        print(f"\nğŸ“¦ å®‰è£…ç¼ºå¤±çš„åŒ…: {', '.join(missing_packages)}")
        import subprocess
        
        # ç‰¹æ®Šå¤„ç†æŸäº›åŒ…çš„å®‰è£…
        install_commands = []
        for pkg in missing_packages:
            if pkg == 'opencv-python':
                install_commands.append('pip install opencv-python-headless')
            elif pkg == 'rapidocr':
                install_commands.append('pip install rapidocr')
            else:
                install_commands.append(f'pip install {pkg}')
        
        for cmd in install_commands:
            print(f"æ‰§è¡Œ: {cmd}")
            result = subprocess.run(cmd.split(), capture_output=True, text=True)
            if result.returncode != 0:
                print(f"âŒ å®‰è£…å¤±è´¥: {cmd}")
                print(result.stderr)
            else:
                print(f"âœ… å®‰è£…æˆåŠŸ")
    
    # 3. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
    print(f"\n3ï¸âƒ£ ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹...")
    
    # ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹ä¸‹è½½è„šæœ¬
    try:
        from init_models import init_models
        success = init_models(skip_i3d=True)  # åœ¨Colabä¸­è·³è¿‡I3Dæ¨¡å‹ä»¥èŠ‚çœç©ºé—´
        if not success:
            print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
            return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å‡ºé”™: {e}")
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæ‰‹åŠ¨ä¸‹è½½æ ¸å¿ƒæ¨¡å‹
        print("ğŸ”„ å°è¯•å¤‡ç”¨ä¸‹è½½æ–¹æ¡ˆ...")
        if not download_core_models():
            return False
    
    # 4. åˆ›å»ºç¤ºä¾‹è„šæœ¬
    print(f"\n4ï¸âƒ£ åˆ›å»ºå¿«é€Ÿæµ‹è¯•è„šæœ¬...")
    create_colab_examples()
    
    # 5. éªŒè¯å®‰è£…
    print(f"\n5ï¸âƒ£ éªŒè¯å®‰è£…...")
    if verify_installation():
        print(f"\nğŸ‰ ProPainter Colabç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼")
        print_usage_guide()
        return True
    else:
        print(f"\nâŒ å®‰è£…éªŒè¯å¤±è´¥")
        return False

def download_core_models():
    """å¤‡ç”¨æ¨¡å‹ä¸‹è½½æ–¹æ¡ˆ"""
    import requests
    from tqdm import tqdm
    import os
    from pathlib import Path
    
    # åˆ›å»ºweightsç›®å½•
    weights_dir = Path('weights')
    weights_dir.mkdir(exist_ok=True)
    
    # æ ¸å¿ƒæ¨¡å‹ï¼ˆè·³è¿‡I3Dä»¥èŠ‚çœç©ºé—´å’Œæ—¶é—´ï¼‰
    core_models = {
        'ProPainter.pth': 'https://github.com/sczhou/ProPainter/releases/download/v0.1.0/ProPainter.pth',
        'recurrent_flow_completion.pth': 'https://github.com/sczhou/ProPainter/releases/download/v0.1.0/recurrent_flow_completion.pth',
        'raft-things.pth': 'https://github.com/sczhou/ProPainter/releases/download/v0.1.0/raft-things.pth',
    }
    
    for model_name, url in core_models.items():
        model_path = weights_dir / model_name
        
        if model_path.exists():
            print(f"âœ… å·²å­˜åœ¨: {model_name}")
            continue
        
        print(f"ğŸ“¥ ä¸‹è½½: {model_name}")
        
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(model_path, 'wb') as f, tqdm(
                desc=model_name,
                total=total_size,
                unit='B',
                unit_scale=True
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
            
            print(f"âœ… å®Œæˆ: {model_name}")
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥ {model_name}: {e}")
            return False
    
    return True

def create_colab_examples():
    """åˆ›å»ºColabç¤ºä¾‹è„šæœ¬"""
    
    # åˆ›å»ºå¿«é€Ÿæµ‹è¯•è„šæœ¬
    quick_test_script = '''# ProPainter å¿«é€Ÿæµ‹è¯•è„šæœ¬

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

def quick_test():
    """å¿«é€Ÿæµ‹è¯•ProPainteræ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    
    print("ğŸ§ª ProPainter å¿«é€Ÿæµ‹è¯•")
    print("-" * 40)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    weights_dir = Path('weights')
    required_models = ['ProPainter.pth', 'recurrent_flow_completion.pth', 'raft-things.pth']
    
    for model in required_models:
        model_path = weights_dir / model
        if model_path.exists():
            size_mb = model_path.stat().st_size / (1024*1024)
            print(f"âœ… {model} ({size_mb:.1f}MB)")
        else:
            print(f"âŒ {model} - æ–‡ä»¶ç¼ºå¤±")
            return False
    
    # æµ‹è¯•OCRåŠŸèƒ½
    try:
        from rapidocr import RapidOCR
        ocr = RapidOCR()
        print("âœ… OCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ OCRå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•PyTorch CUDA
    import torch
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}")
        print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    
    print("\\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ProPainterå·²å‡†å¤‡å°±ç»ª")
    return True

if __name__ == "__main__":
    quick_test()
'''
    
    with open('quick_test.py', 'w', encoding='utf-8') as f:
        f.write(quick_test_script)
    
    # åˆ›å»ºä½¿ç”¨ç¤ºä¾‹
    usage_example = '''# ProPainter ä½¿ç”¨ç¤ºä¾‹

# 1. ç”ŸæˆOCRæ©ç ï¼ˆå»é™¤æ–‡å­—/å­—å¹•/æ°´å°ï¼‰
!python generate_ocr_mask.py -i /path/to/your/video.mp4 -o ocr_masks --confidence 0.6

# 2. ä½¿ç”¨ProPainterè¿›è¡Œè§†é¢‘ä¿®å¤
!python inference_propainter.py -i /path/to/your/video.mp4 -m ocr_masks/video_name_mask --fp16

# 3. å¤„ç†å›¾åƒåºåˆ—
!python generate_ocr_mask.py -i /path/to/image/folder -o masks
!python inference_propainter.py -i /path/to/image/folder -m masks/folder_name_mask

# 4. é«˜çº§é€‰é¡¹
!python inference_propainter.py \\
    -i input_video.mp4 \\
    -m mask_folder \\
    --width 1280 \\
    --height 720 \\
    --fp16 \\
    --subvideo_length 60 \\
    --save_frames
'''
    
    with open('usage_examples.py', 'w', encoding='utf-8') as f:
        f.write(usage_example)
    
    print("âœ… å·²åˆ›å»ºç¤ºä¾‹è„šæœ¬:")
    print("   - quick_test.py: å¿«é€ŸéªŒè¯å®‰è£…")
    print("   - usage_examples.py: ä½¿ç”¨ç¤ºä¾‹")

def verify_installation():
    """éªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸ"""
    
    try:
        # æ£€æŸ¥æ ¸å¿ƒä¾èµ–
        import torch
        import torchvision
        import cv2
        import numpy as np
        from rapidocr import RapidOCR
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        from pathlib import Path
        weights_dir = Path('weights')
        required_models = ['ProPainter.pth', 'recurrent_flow_completion.pth', 'raft-things.pth']
        
        for model in required_models:
            if not (weights_dir / model).exists():
                print(f"âŒ ç¼ºå¤±æ¨¡å‹: {model}")
                return False
        
        # ç®€å•çš„åŠŸèƒ½æµ‹è¯•
        from model.misc import get_device
        device = get_device()
        print(f"âœ… è®¾å¤‡æ£€æµ‹: {device}")
        
        # OCRæµ‹è¯•
        ocr = RapidOCR()
        print("âœ… OCRå¼•æ“: æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False

def print_usage_guide():
    """æ‰“å°ä½¿ç”¨æŒ‡å—"""
    
    guide = """
ğŸ¯ ä½¿ç”¨æŒ‡å—:

1ï¸âƒ£ OCRæ©ç ç”Ÿæˆï¼ˆå»é™¤æ–‡å­—/å­—å¹•/æ°´å°ï¼‰:
   python generate_ocr_mask.py -i your_video.mp4 -o masks

2ï¸âƒ£ è§†é¢‘ä¿®å¤ï¼ˆæ¨èè®¾ç½®ï¼‰:
   python inference_propainter.py -i your_video.mp4 -m masks/video_mask --fp16

3ï¸âƒ£ å†…å­˜ä¼˜åŒ–è®¾ç½®ï¼ˆé€‚ç”¨äºå¤§è§†é¢‘ï¼‰:
   python inference_propainter.py -i video.mp4 -m masks --fp16 --subvideo_length 40

4ï¸âƒ£ å¿«é€Ÿæµ‹è¯•:
   python quick_test.py

ğŸ“ æ›´å¤šç¤ºä¾‹è¯·æŸ¥çœ‹: usage_examples.py

ğŸ’¡ æç¤º:
   - ä½¿ç”¨ --fp16 å¯ä»¥å‡å°‘GPUå†…å­˜å ç”¨
   - è°ƒæ•´ --subvideo_length æ§åˆ¶å†…å­˜ä½¿ç”¨
   - OCRç½®ä¿¡åº¦å»ºè®®è®¾ç½®ä¸º 0.5-0.8
   - å¤§è§†é¢‘å»ºè®®å…ˆåˆ†æ®µå¤„ç†
    """
    
    print(guide)

# å¦‚æœæ˜¯ç›´æ¥è¿è¡Œæ­¤è„šæœ¬
if __name__ == "__main__":
    success = init_propainter_colab()
    if not success:
        exit(1)