{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProPainter åˆå§‹åŒ–è„šæœ¬\n",
    "\n",
    "è¿™ä¸ªNotebookå°†è‡ªåŠ¨å®ŒæˆProPainterçš„ç¯å¢ƒé…ç½®å’Œæ¨¡å‹ä¸‹è½½ï¼Œé€‚ç”¨äºGoogle Colabç¯å¢ƒã€‚\n",
    "\n",
    "## åŠŸèƒ½è¯´æ˜\n",
    "- ğŸ”§ è‡ªåŠ¨å®‰è£…æ‰€éœ€ä¾èµ–\n",
    "- ğŸ“¥ ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆçº¦400MBï¼‰\n",
    "- ğŸ§ª éªŒè¯å®‰è£…å®Œæ•´æ€§\n",
    "- ğŸ“ æä¾›ä½¿ç”¨ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–\n",
    "print(\"ğŸš€ ProPainter åˆå§‹åŒ–å¼€å§‹...\")\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# æ£€æŸ¥GPU\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"âœ… GPU: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "    else:\n",
    "        print(\"âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè¿è¡Œ\")\n",
    "except:\n",
    "    print(\"ğŸ“¦ PyTorchæœªå®‰è£…ï¼Œç¨åå°†è‡ªåŠ¨å®‰è£…\")\n",
    "\n",
    "# å®‰è£…å¿…è¦çš„åŒ…\n",
    "required_packages = [\n",
    "    'torch>=2.0.0',\n",
    "    'torchvision>=0.15.0', \n",
    "    'opencv-python-headless',\n",
    "    'rapidocr',\n",
    "    'onnxruntime-gpu',\n",
    "    'scipy',\n",
    "    'matplotlib',\n",
    "    'imageio-ffmpeg',\n",
    "    'tqdm'\n",
    "]\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\")\n",
    "for package in required_packages:\n",
    "    print(f\"å®‰è£…: {package}\")\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'install', package], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"âœ… {package}\")\n",
    "    else:\n",
    "        print(f\"âŒ {package} - å®‰è£…å¤±è´¥\")\n",
    "        print(result.stderr)\n",
    "\n",
    "print(\"\\nâœ… ä¾èµ–å®‰è£…å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬äºŒæ­¥ï¼šä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def download_model(url, filename):\n",
    "    \"\"\"ä¸‹è½½æ¨¡å‹æ–‡ä»¶\"\"\"\n",
    "    weights_dir = Path('weights')\n",
    "    weights_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    file_path = weights_dir / filename\n",
    "    \n",
    "    if file_path.exists():\n",
    "        print(f\"âœ… å·²å­˜åœ¨: {filename}\")\n",
    "        return True\n",
    "    \n",
    "    print(f\"ğŸ“¥ ä¸‹è½½: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(file_path, 'wb') as f, tqdm(\n",
    "            desc=filename,\n",
    "            total=total_size,\n",
    "            unit='B',\n",
    "            unit_scale=True\n",
    "        ) as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "        \n",
    "        print(f\"âœ… å®Œæˆ: {filename}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¸‹è½½å¤±è´¥ {filename}: {e}\")\n",
    "        if file_path.exists():\n",
    "            file_path.unlink()\n",
    "        return False\n",
    "\n",
    "# æ¨¡å‹ä¸‹è½½åˆ—è¡¨\n",
    "models = {\n",
    "    'ProPainter.pth': 'https://github.com/sczhou/ProPainter/releases/download/v0.1.0/ProPainter.pth',\n",
    "    'recurrent_flow_completion.pth': 'https://github.com/sczhou/ProPainter/releases/download/v0.1.0/recurrent_flow_completion.pth',\n",
    "    'raft-things.pth': 'https://github.com/sczhou/ProPainter/releases/download/v0.1.0/raft-things.pth',\n",
    "}\n",
    "\n",
    "print(\"ğŸ”½ å¼€å§‹ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹...\")\n",
    "print(\"â±ï¸  é¢„è®¡éœ€è¦3-5åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦ï¼‰\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "success_count = 0\n",
    "for filename, url in models.items():\n",
    "    if download_model(url, filename):\n",
    "        success_count += 1\n",
    "\n",
    "print(f\"\\nğŸ“Š ä¸‹è½½ç»“æœ: {success_count}/{len(models)} ä¸ªæ¨¡å‹\")\n",
    "\n",
    "if success_count == len(models):\n",
    "    print(\"ğŸ‰ æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼\")\n",
    "else:\n",
    "    print(\"âš ï¸  éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬ä¸‰æ­¥ï¼šéªŒè¯å®‰è£…\n",
    "def verify_installation():\n",
    "    \"\"\"éªŒè¯ProPainterå®‰è£…\"\"\"\n",
    "    print(\"ğŸ§ª éªŒè¯ProPainterå®‰è£…...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶\n",
    "    weights_dir = Path('weights')\n",
    "    required_models = ['ProPainter.pth', 'recurrent_flow_completion.pth', 'raft-things.pth']\n",
    "    \n",
    "    model_check = True\n",
    "    for model in required_models:\n",
    "        model_path = weights_dir / model\n",
    "        if model_path.exists():\n",
    "            size_mb = model_path.stat().st_size / (1024*1024)\n",
    "            print(f\"âœ… {model} ({size_mb:.1f}MB)\")\n",
    "        else:\n",
    "            print(f\"âŒ {model} - æ–‡ä»¶ç¼ºå¤±\")\n",
    "            model_check = False\n",
    "    \n",
    "    # æ£€æŸ¥æ ¸å¿ƒä¾èµ–\n",
    "    try:\n",
    "        import torch\n",
    "        import torchvision\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        from rapidocr import RapidOCR\n",
    "        print(\"âœ… æ ¸å¿ƒä¾èµ–åŒ…: æ­£å¸¸\")\n",
    "        \n",
    "        # æµ‹è¯•OCRå¼•æ“\n",
    "        ocr = RapidOCR()\n",
    "        print(\"âœ… OCRå¼•æ“: æ­£å¸¸\")\n",
    "        \n",
    "        # æµ‹è¯•è®¾å¤‡\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "            print(f\"âœ… CUDAè®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print(\"âœ… CPUè®¾å¤‡: å¯ç”¨\")\n",
    "        \n",
    "        dependency_check = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥: {e}\")\n",
    "        dependency_check = False\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if model_check and dependency_check:\n",
    "        print(\"ğŸ‰ éªŒè¯é€šè¿‡ï¼ProPainterå·²å‡†å¤‡å°±ç»ª\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"âŒ éªŒè¯å¤±è´¥ï¼Œè¯·é‡æ–°è¿è¡Œåˆå§‹åŒ–\")\n",
    "        return False\n",
    "\n",
    "# æ‰§è¡ŒéªŒè¯\n",
    "success = verify_installation()\n",
    "\n",
    "if success:\n",
    "    print(\"\\nğŸ¯ ä¸‹ä¸€æ­¥: è¿è¡Œä½¿ç”¨ç¤ºä¾‹ï¼\")\n",
    "else:\n",
    "    print(\"\\nğŸ”„ è¯·é‡æ–°è¿è¡Œä¸Šé¢çš„ä»£ç å—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬å››æ­¥ï¼šä½¿ç”¨ç¤ºä¾‹\n",
    "print(\"ğŸ“ ProPainter ä½¿ç”¨ç¤ºä¾‹\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "usage_examples = \"\"\"\n",
    "# 1. åŸºç¡€ä½¿ç”¨æµç¨‹\n",
    "\n",
    "## æ­¥éª¤1: ç”ŸæˆOCRæ©ç ï¼ˆå»é™¤æ–‡å­—/å­—å¹•/æ°´å°ï¼‰\n",
    "!python generate_ocr_mask.py -i /path/to/your/video.mp4 -o ocr_masks --confidence 0.6\n",
    "\n",
    "## æ­¥éª¤2: ä½¿ç”¨ProPainterè¿›è¡Œè§†é¢‘ä¿®å¤  \n",
    "!python inference_propainter.py -i /path/to/your/video.mp4 -m ocr_masks/video_name_mask --fp16\n",
    "\n",
    "# 2. æ¨èè®¾ç½®ï¼ˆé€‚ç”¨äºColabï¼‰\n",
    "\n",
    "## å†…å­˜ä¼˜åŒ–è®¾ç½®\n",
    "!python inference_propainter.py \\\\\n",
    "    -i input_video.mp4 \\\\\n",
    "    -m mask_folder \\\\\n",
    "    --fp16 \\\\\n",
    "    --subvideo_length 40 \\\\\n",
    "    --height 720 \\\\\n",
    "    --width 1280\n",
    "\n",
    "# 3. å¤„ç†å›¾åƒåºåˆ—\n",
    "!python generate_ocr_mask.py -i /path/to/image/folder -o masks\n",
    "!python inference_propainter.py -i /path/to/image/folder -m masks/folder_name_mask\n",
    "\n",
    "# 4. é«˜çº§OCRè®¾ç½®\n",
    "!python generate_ocr_mask.py \\\\\n",
    "    -i video.mp4 \\\\\n",
    "    -o masks \\\\\n",
    "    --confidence 0.7 \\\\\n",
    "    --dilation 8 \\\\\n",
    "    --margin 15 \\\\\n",
    "    --sample_rate 2\n",
    "\n",
    "# 5. å‚æ•°è¯´æ˜\n",
    "\n",
    "OCRå‚æ•°:\n",
    "- --confidence: æ–‡å­—æ£€æµ‹ç½®ä¿¡åº¦ (0.5-0.8æ¨è)\n",
    "- --dilation: æ©ç è†¨èƒ€å¤§å° (5-10æ¨è)\n",
    "- --margin: æ–‡å­—æ¡†è¾¹è· (10-20æ¨è)\n",
    "- --sample_rate: å¸§é‡‡æ ·ç‡ (1=å…¨éƒ¨, 2=éš”å¸§)\n",
    "\n",
    "ProPainterå‚æ•°:\n",
    "- --fp16: ä½¿ç”¨åŠç²¾åº¦ï¼ŒèŠ‚çœæ˜¾å­˜\n",
    "- --subvideo_length: å­è§†é¢‘é•¿åº¦ï¼Œæ§åˆ¶å†…å­˜ä½¿ç”¨\n",
    "- --width/--height: å¤„ç†åˆ†è¾¨ç‡\n",
    "- --save_frames: ä¿å­˜æ‰€æœ‰å¸§å›¾åƒ\n",
    "\"\"\"\n",
    "\n",
    "print(usage_examples)\n",
    "\n",
    "# åˆ›å»ºå¿«é€Ÿæµ‹è¯•å‡½æ•°\n",
    "def create_test_data():\n",
    "    \"\"\"åˆ›å»ºæµ‹è¯•æ•°æ®\"\"\"\n",
    "    print(\"\\nğŸ§ª åˆ›å»ºæµ‹è¯•æ•°æ®...\")\n",
    "    \n",
    "    # å¦‚æœæœ‰ç¤ºä¾‹è§†é¢‘ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¸‹è½½é€»è¾‘\n",
    "    test_script = '''\n",
    "# æµ‹è¯•è„šæœ¬ç¤ºä¾‹\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•è§†é¢‘ï¼ˆå¸¦æ–‡å­—ï¼‰\n",
    "def create_test_video(output_path=\"test_video.mp4\", duration=3, fps=24):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (640, 480))\n",
    "    \n",
    "    for i in range(duration * fps):\n",
    "        # åˆ›å»ºå½©è‰²èƒŒæ™¯\n",
    "        frame = np.random.randint(100, 200, (480, 640, 3), dtype=np.uint8)\n",
    "        \n",
    "        # æ·»åŠ æ–‡å­—\n",
    "        cv2.putText(frame, f\"Frame {i+1}\", (50, 50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Test Watermark\", (400, 400), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"âœ… æµ‹è¯•è§†é¢‘å·²åˆ›å»º: {output_path}\")\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•\n",
    "if __name__ == \"__main__\":\n",
    "    create_test_video()\n",
    "    print(\"ç°åœ¨å¯ä»¥è¿è¡Œ:\")\n",
    "    print(\"!python generate_ocr_mask.py -i test_video.mp4 -o test_masks\")\n",
    "    print(\"!python inference_propainter.py -i test_video.mp4 -m test_masks/test_video_mask --fp16\")\n",
    "'''\n",
    "    \n",
    "    with open('create_test_video.py', 'w') as f:\n",
    "        f.write(test_script)\n",
    "    \n",
    "    print(\"âœ… æµ‹è¯•è„šæœ¬å·²åˆ›å»º: create_test_video.py\")\n",
    "    print(\"è¿è¡Œ !python create_test_video.py åˆ›å»ºæµ‹è¯•è§†é¢‘\")\n",
    "\n",
    "create_test_data()\n",
    "\n",
    "print(\"\\nğŸ‰ ProPainter åˆå§‹åŒ–å®Œæˆï¼\")\n",
    "print(\"ğŸ“š ä½¿ç”¨ä¸Šé¢çš„ç¤ºä¾‹ä»£ç å¼€å§‹ä½ çš„è§†é¢‘å¤„ç†ä¹‹æ—…å§ï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}